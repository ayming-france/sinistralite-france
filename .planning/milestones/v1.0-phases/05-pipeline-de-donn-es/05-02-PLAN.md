---
phase: 05-pipeline-de-donn-es
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - data/pipeline/parse_pdf.py
  - data/pipeline/requirements.txt
  - data/pipeline/README.md
autonomous: true
requirements:
  - PIPE-01
  - PIPE-03
  - PIPE-04

must_haves:
  truths:
    - "parse_pdf.py accepte --pdf-dir en argument CLI et refuse de tourner avec un chemin invalide"
    - "requirements.txt liste les 3 dépendances (requests, openpyxl, pdfplumber)"
    - "Le README explique les prérequis, la commande à lancer et la fréquence de mise à jour"
  artifacts:
    - path: "data/pipeline/parse_pdf.py"
      provides: "Parsing des fiches PDF par NAF pour les données démographiques"
      contains: "argparse"
    - path: "data/pipeline/requirements.txt"
      provides: "Dépendances Python du pipeline"
      contains: "pdfplumber"
    - path: "data/pipeline/README.md"
      provides: "Documentation du pipeline"
      contains: "refresh_data.py"
  key_links:
    - from: "data/pipeline/parse_pdf.py"
      to: "data/pipeline/refresh_data.py"
      via: "import ou appel CLI depuis refresh_data"
      pattern: "parse_pdf|parse_all_pdfs"
---

<objective>
Copier et adapter parse_pdf.py, créer requirements.txt et le README du pipeline.

Purpose: Compléter le pipeline avec le parsing PDF (données démographiques par NAF) et la documentation nécessaire pour qu'un utilisateur puisse lancer une mise à jour des données de manière autonome.
Output: `data/pipeline/parse_pdf.py` avec CLI configurable, `requirements.txt`, `README.md`.
</objective>

<execution_context>
@/Users/encarv/.claude/get-shit-done/workflows/execute-plan.md
@/Users/encarv/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-pipeline-de-donn-es/05-RESEARCH.md
@/Users/encarv/.claude/bpo/data/parse_pdf.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Copier et adapter parse_pdf.py</name>
  <files>data/pipeline/parse_pdf.py</files>
  <action>
Copier `/Users/encarv/.claude/bpo/data/parse_pdf.py` (393 lignes) vers `data/pipeline/parse_pdf.py`.

Appliquer les adaptations suivantes :

1. **Rendre PDF_DIR configurable :** Supprimer la ligne hardcodée `PDF_DIR = Path("/Users/encarv/Desktop/...")`. Ajouter un bloc `argparse` dans `main()` :
   ```python
   parser = argparse.ArgumentParser(description="Parse les fiches PDF NAF pour extraire les données démographiques")
   parser.add_argument("--pdf-dir", required=True, help="Chemin vers le dossier contenant les fichiers NAF_*.pdf")
   args = parser.parse_args()
   pdf_dir = Path(args.pdf_dir)
   ```
   Ajouter une vérification d'existence du dossier avec message d'erreur clair et `sys.exit(1)`.

2. **Vérifier le contenu du dossier :** Après validation du chemin, vérifier qu'il contient au moins un fichier PDF correspondant au pattern `NAF_*.pdf`. Afficher un avertissement si aucun PDF trouvé.

3. **Supprimer les chemins absolus :** Aucune référence `/Users/encarv/` ne doit subsister.

4. **Nettoyer les imports :** Retirer les imports non utilisés. Ajouter `import argparse` et `import sys` si absents.

5. **Fonction parse_all_pdfs :** S'assurer qu'elle accepte `pdf_dir` en paramètre (pas en variable globale). Si elle est appelée depuis refresh_data.py, l'interface doit être `parse_all_pdfs(pdf_dir: Path) -> dict`.

6. **Messages de log :** Améliorer les messages pour indiquer le nombre de PDFs trouvés, le PDF en cours de traitement, et un résumé final.
  </action>
  <verify>
    <automated>cd /Users/encarv/.claude/datagouv && python3 -c "import ast; ast.parse(open('data/pipeline/parse_pdf.py').read()); print('Syntax OK')" && grep -q "argparse" data/pipeline/parse_pdf.py && grep -q "\-\-pdf-dir" data/pipeline/parse_pdf.py && ! grep -q "/Users/encarv" data/pipeline/parse_pdf.py && echo "ALL CHECKS PASSED"</automated>
    <manual>Vérifier que le script est lisible et bien structuré</manual>
  </verify>
  <done>parse_pdf.py existe dans data/pipeline/, accepte --pdf-dir en CLI, ne contient aucun chemin absolu hardcodé, et parse correctement la syntaxe Python</done>
</task>

<task type="auto">
  <name>Task 2: Créer requirements.txt et README.md</name>
  <files>data/pipeline/requirements.txt, data/pipeline/README.md</files>
  <action>
**requirements.txt :**
Créer `data/pipeline/requirements.txt` avec les 3 dépendances identifiées dans la recherche :
```
requests>=2.31
openpyxl>=3.1
pdfplumber>=0.10
```

**README.md :**
Créer `data/pipeline/README.md` en français avec accents. Contenu obligatoire :

1. **Titre :** "Pipeline de données" avec sous-titre "Sinistralité France"
2. **Prérequis :** Python 3.10+, installation des dépendances via `pip install -r requirements.txt`, les PDFs par NAF doivent être téléchargés manuellement depuis ameli.fr (optionnel, uniquement pour les données démographiques)
3. **Lancer une mise à jour :**
   - Commande de base : `python refresh_data.py` (télécharge les Excel, génère les JSON)
   - Avec PDF : `python refresh_data.py --pdf-dir /chemin/vers/pdfs`
   - Les fichiers JSON sont écrits dans `data/` (dossier parent)
4. **Fichiers produits :** at-data.json, mp-data.json, trajet-data.json avec description brève de chacun
5. **Fréquence de mise à jour :** Les données ameli.fr sont publiées annuellement. Relancer le pipeline à chaque nouvelle publication.
6. **Sources de données :** Lister les URLs ameli.fr utilisées (Excel AT/MP/Trajet et fiches PDF par NAF)

Le README doit utiliser les accents français corrects dans tout le texte visible (é, è, ê, à, ç, etc.). Ne PAS utiliser de tiret cadratin.
  </action>
  <verify>
    <automated>cd /Users/encarv/.claude/datagouv && test -f data/pipeline/requirements.txt && test -f data/pipeline/README.md && grep -q "pdfplumber" data/pipeline/requirements.txt && grep -q "openpyxl" data/pipeline/requirements.txt && grep -q "requests" data/pipeline/requirements.txt && grep -q "refresh_data.py" data/pipeline/README.md && echo "ALL CHECKS PASSED"</automated>
    <manual>Vérifier la clarté du README et l'exactitude des commandes</manual>
  </verify>
  <done>requirements.txt liste les 3 dépendances, README.md explique les prérequis, commandes et fréquence de mise à jour en français avec accents corrects</done>
</task>

</tasks>

<verification>
- `python3 -c "import ast; ast.parse(open('data/pipeline/parse_pdf.py').read())"` passe
- parse_pdf.py contient `argparse` et `--pdf-dir`
- Aucune occurrence de `/Users/encarv` dans parse_pdf.py
- requirements.txt contient requests, openpyxl, pdfplumber
- README.md contient les sections prérequis, commande, fréquence
</verification>

<success_criteria>
Le dossier data/pipeline/ contient parse_pdf.py (configurable via CLI), requirements.txt (3 dépendances), et README.md (documentation complète en français). Un utilisateur peut lire le README et comprendre comment lancer le pipeline.
</success_criteria>

<output>
After completion, create `.planning/phases/05-pipeline-de-donn-es/05-02-SUMMARY.md`
</output>
